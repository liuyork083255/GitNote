
粘包概念：
	比如客户端发送给服务端信息，数据写一点就发送，写一点就发送，服务端接到数据首先是存入ByteBuf，这个时候，
	在 ByteBuf 里面并不知道一条完整的数据的头和尾（也就是前后分割点），那么服务端就无法分割出完整的消息。
	
	客户端仔细分析：
		首先是客户端的代码将数据写一条然后刷新一次，保证写入自己这边的channel，然后接着又写，又刷新 ...
		不要把channel理解成真正的传输通道了，它只是抽象便于理解而已，发送到channel的每一个数据都会经过客户端这边的tcp协议层，这个时候就发生了粘包，
		它会把多条信息进行粘包一起发送出去，这是为了提高tcp层的网络效率（试想一下：每发一k的数据就发送，那岂不是浪费很多网络资源）
		
	服务端细节分析：
		首先是从协议层的tcp接到了消息，这条消息可能是多条组合而成的，但是它自己肯定是不晓得的，直接传给上面的应用层，
		这个时候时候服务端的 handler 就收到了消息，执行 channelRead 操作。所以很有可能读的是N条消息组合而成的消息。
		
		
注意：粘不粘包不是发生应用层的，而是在tcp协议层，我们是控制不了的，只能去解决，比如设定分隔符，那么是如何处理的呢？需要一些概念：

	数据从客户端发过来，到了服务端的tcp，然后进入应用层的 bytebuf 缓冲区里面，这时候其实最先处理数据的不是业务逻辑的 handler ，
	而是我们设置在 pipeline 里面最前面的 handler，这个handler需要继承相关解码类重写decode方法，它会依次遍历ByteBuf中的可读字节，
	判断是否有预先设置的分隔符，如何有，将切割出来作为单独一条消息处理。最后才是交给后面的业务 handler 处理。
















